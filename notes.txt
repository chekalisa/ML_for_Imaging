1.118040680885315

v2.functional.gaussian_noise(inpt[, mean, ...])

v2.functional.gaussian_blur(inpt, kernel_size)

v2.GaussianBlur(kernel_size[, sigma])

v2.functional.vertical_flip(inpt)

v2.RandomCrop(size[, padding, ...])

 1.0162482261657715


After Part A is done:
    val_auc            0.8230335712432861
        val_loss            0.9988945722579956


PartB LeNET:
   val_auc            0.8332706093788147
        val_loss            0.9740522503852844

AlexNet:

      val_auc            0.8792929649353027
        val_loss            0.8816537857055664

ResNet:
  val_auc            0.9240739345550537
        val_loss            0.5740153789520264

GoogleLeNet:
val_auc            0.9191032648086548
        val_loss            0.7252408862113953

SqueezeNet:
val_auc            0.8999052047729492
        val_loss            0.7830920219421387

Own implementation of ResNet (after epoch0; 19):
val_auc             0.860666036605835
        val_loss            0.8847926259040833

5 epochs:
val_auc            0.9094974994659424
        val_loss            0.6875401139259338

20 epochs:

  val_auc            0.9094974994659424
        val_loss            0.6875401139259338

With pre-trained ResNet, increasing the number of epochs did not improve (did not find this)

tutorial resnet (30)

val_auc            0.9216341972351074
        val_loss            0.5862911343574524

Resnet pretrained (32) :
   val_auc            0.9240739345550537
        val_loss            0.5740153789520264

       test_auc            0.9172621965408325
        test_loss           0.5972970724105835

